# Summarized System Design Problems
## Сервис сокращения ссылок типа TinyURL
### 1. Зачем нам нужна сокращалка ссылок?
Сокращалка ссылок создает короткие алиасы для длинных ссылок. Мы отдаем ей длинную ссылку, получаем в ответ короткую и отправляем ее другу. Друг переходит по короткой ссылке и получает редирект на исходный адрес.

Сокращалки ссылок используются для оптимизации обмена между устройствами, трекингом исходных ссылок для целей аналитики или скрытия исходных адресов.

### 2. Требования и цели системы
Сокращалка ссылок должна удовлетворять следующим требованиям

**Функциональные требования:**
- Получив ссылку, наш сервис должен сгенериротьва короткий уникальный алиас для нее. Это называется короткой ссылкой. Эта ссылка должна быть достаточно короткой, чтобы ее можно было легко скопировать и вставить в приложение.
- Когда пользователь переходит по короткой ссылке, наш сервис должен редиректнуть его на исходный адрес.
- Пользователь должен иметь возможность при желании выбрать собственный текст для короткой ссылки.
- Ссылка должна устаревать через некоторое время. Пользователь может выбрать какое время будет актуальна ссылка.

**Нефункциональные требования:**
- Система должна иметь высокую надежность. Это требуется поскольку при падении нашей системы, короткие ссылки перестанут работать.
- Редирект на исходный адрес должен происходить в реальном времени с минимальной задержкой.
- Сокращенные ссылки должны быть непредстазуемы, неугадываемы.

**Дополнительные требования:**
- Нужна аналитика (сколько раз происходили редиректы, откуда приходили пользователи).
- Сервис так же должен быть доступен через REST API для других сервисов.

### 3. Оценка емкости и ограничений
Наша система будет нагружена по чтению. Запросов на кароткие урлы будет больше, чем на их сокращение. Предположим, что соотношение будет 100:1

**Оценка количества запросов:** Предположим мы имеет 500 млн новых урлов в месяц. С коэфф. 100:1 мы молучим 50 млрд. чтений за тот же период.

Какое будет число запросов (RPS) для нашей системы на запись? 

500 млн / (30 дней * 24 часа * 3600 сек) = ~200 URLs/s

С коэфф 100:1 это будет 100 * 200 = 20 К/s записей.

**Оценка хранилища:** Допустим мы сохраняем каждый URL на 5 лет. Поскольку мы ожидаем 500M новых урлов каждый месяц, то общее количество записей в базе будет 30 млрд:

500M * 5Y * 12M = 30 B

Предположим для начала, что каждая запись будет занимать 500 байт (мы уточним эту цифру позже), тогда нам понадобится 15 TB дисквого пространства:

30 billinons * 500bytes = 15 TB

**Оценка трафика:** Для запросов на запись, поскольку мы ожидает 200 записей каждую секунду, мы получим 100KB/s:

200 * 500 bytes = 100KB/s

Для запросов на чтение трафик составит 10 MB/s:

20K * 500 bytes = 10 MB/s

**Оценка памяти:**  Если мы хотим кешировать ссылки, которые чаще всего запрашивают пользователи, то сколько памяти нам нужно для этого? Допустим 20% ссылок генерируют 80% трафика. Сколько памяти нам нужно на эти 20% ссылок?

Раз у нас есть 20K запросов в секунду, мы получим 1.7B запросво в день:

20K * 3600 sec * 24 hour = 1.7B

Чтобы закешировать 20% от этих запросов нам нужно 170 GB памяти:

0.2 * 1.7B * 500 bytes = 170 GB

Поскольку у нас будет много запросов на тот же самый URL, реальные затраты памяти будут ниже, чем 170 GB.

**Итого:** Предполагая 500 млн новых урлов в месяц и коэфф чтения к записи 100:1, мы получим следующие оценки:

![](attachments/Pasted%20image%2020220510143035.png)

### 4. API системы
Мы можем использовать SOAP или REST API для взаимодействия с нашим сервисом. Следующие методы могут использоваться для создания и удаления ссылок.

```
createURL(api_dev_key, original_url, custom_alias=None, user_name=None, expire_date=None)
```

api_dev_key можно использовать для зарегистрированных аккаунтов для троттлинга запросов согласно выделенной квоты.

```
deleteURL(api_dev_key, url_key)
```

url_key - это сокращенный URL

**Как нам определить и предотвратить злонамеренное использование?** Установить лимиты создания и получения ссылок на каждого отдельного разработчика. А если сервис позволяет анонимный доступ? Тогда можно сделать лимиты на создание с конкретного IP и лимиты на чтение на конкретный IP и на отдельные ссылки.

### 5. Дизайн БД, модель данных
Некоторые наблюдения относительно данных, которые нам нужно будет хранить:
- Нам нужно хранить миллиарды строк
- Каждый объект, которым мы храним будет небольшим (меньше 1K)
- Между записями нет связи (кроме того, какой пользователь их создал)
- Наш сервис нагружен по чтению

Нам может понадобиться две базы: одна для хранения информации об URL и другая для хранения информации о пользователях.

![](attachments/Pasted%20image%2020220510150111.png)

**Какую БД мы должны использовать?** NoSQL хранилище типа [DynamoDB](https://en.wikipedia.org/wiki/Amazon_DynamoDB), [Cassandra](https://en.wikipedia.org/wiki/Apache_Cassandra) или [Riak](https://en.wikipedia.org/wiki/Riak) будет наилучшим выбором. Такое хранилищие к тому же будет проще масштабировать.

### 6. Базовый дизайн системы и алгоритмы
Нам нужно определиться каким образом мы будем генерировать короткую форму для данной ссылки.

В примере с TinyURL сокращенные ссылки выглядят так [https://tinyurl.com/rxcsyr3r](https://tinyurl.com/rxcsyr3r). Последние 8 символов в ссылке - это и есть тот ключ, который мы хотим сгененрировать. 

Мы рассмотрим два решения.

#### a. Кодирование исходного URL
Мы можем считать уникальный хэш (MD5 или SHA256) от переданной ссылки. Хэш можно заенкодить для отображения: base36 ([a-z,0-9]) или base62([A-Z,a-z,0-9]), а если добавить еще знаки + и /, то получим base64. Резонным вопросом тут будет, какой длины должен быть короткий ключ? 6, 8 или 10 символов?

- Используя кодировку base64 и ключ длинно 6 символов мы получим 64^6 = 68 млрд возможных строк.
- Для ключа длинной 8 символов получим уже 64^8 - 280 триллионов строк.

В принципе, нам достаточно 68B строку, так что предположим, что ключ будет состоять из 6 символов.

Алгоритм MD5 генерирует 128-битный хеш. После кодирования в BASE64 мы получим строку более 21 символа в длину (т.к. каждый символ в base64 кодирует 6 бит)

Как нам выбрать ключ, если на него у нас есть только от 6 до 8 символов? 

Можно выбрать только часть хеша для формирования ключа. Это может привести к появлению дублей. Можно попробовать брать символы для ключа из разных мест строки или менять их местами (это в любом случае выглядит как костыль).

А есть ли еще минусы у такого решения?
- Если несколько пользователей добавят один и тот же URL - они получат один и тот же ключ, что может быть неприемлемо.
- Если часть ключа будет URL-encoded, то такая же ссылка, но не заэнкоженная будут давать разные ключи.

Как вариант, мы можем добавлять некое монотонно возрастающее значение к каждому из кодируемых урлов. Нам не обязательно сохранять это значение в базе, оно нам нужно просто, чтобы делать каждую ссылку уникальной. Проблема тут будет в том как в принципе получить моотонно возрастающую последовательность числел. Должны ли они все быть уникальными? Могут ли они пересекаться?

Другим решением может быть добавление ID пользвоателя к строки перед кодированием, но это работает только зарегистрированных пользователей. Для незарегистрированных мы можем попробовать сгенерировать пользователю свой уникальный ключ на данную конкретную сессию.

![](attachments/Pasted%20image%2020220510153541.png)

#### b. Генерация ключей оффлайн
Мы можем завести отдельный сервис для генерации ключей (Key Generation Service), который бы генерировал уникальные случайные ключи и складывал их в базу (key-DB). Каждый раз, когда нам нужно добавить новую ссылку, мы можешь пойти в базу и взять оттуда новый ключ. Просто и быстро. Нам не нужно кодировать ссылки или заботиться об уникальности ключей, так как сервис генерации ключей делает это за нас.

**Может ли конкуррентность стать проблемой?** Как только ключ использован, мы должны пометить его в базе, чтобы никто другой не смог его использовать повторно. Если несколько северов получают ключи из базы конкуррентно может возникнуть ситуация, когда сразу несколько из них получат один и тот же ключ.

Сервера могут использовать KGS чтобы получать/отмечать ключи в БД. KGS может хранить ключи в двух базах: в одной ключи, которые еще не были использованы, в другой ключ, которые уже использовались. Как только KGS отдает ключ кому-то, он должен переносить его из первой таблицы во вторую.

KGS может хранить некототорое количество ключей в памяти, чтобы выдать их как можно быстрее. Для простоты реализации, KGS может сразу переносить ключ в использованные как только он загрузил его из базы. Если он умрет, мы потеряем часть ключей, но эта потеря будет не критична.

KGS должен следить за тем, чтобы не выдавать один и тот же ключ нескольким серверам. Для этого нужно синхронизировать доступ или ввести какой-то вариант локов на структуру, которая хранит ключи.

**Какой будет размер у базы для ключей?** В кодировкой base64, мы можем сгенерировать 68B значений ключа из 6 символов. Если на 1 символ будет уходить 1 байт, нам потребуется:

6 символов * 68 млрд. ключей = 412 GB

**Является ли KGS единой точкой отказа?** Конечно является. Мы можем иметь стендбай реплику сервиса, чтобы при падении основного сервера его место занял резервный.

**Могут ли сервера приложений кешировать ключи, полученные из key-DB?** Могут и это повысит производительность. Но в этом случае при падении сервера мы потеряем определенное количество ключей. Поскольку у нас ключей с запасом, мы можем себе это позволить.

**Как нам выполнять поиск ключей?** Мы можем воспользоваться механизмами протокола HTTP. Если ключ найден, отдаем 302 редиррект на нужную страницу. Если ключа нет, отдаем 404 или редиректим пользователя на главную страницу сервиса.

**Нужно ли нам задавать ограничения на кастомные ключи?** Да, мы можем их задать. Например можно ограничить длину кастомного ключа 16 символами.

![](attachments/Pasted%20image%2020220510155843.png)

### 7. Партицирование и репликация
Наша база скорее всего не взелет за один сервер, для масштабирования ее на требуемые объемы и производительность нам нужно партицировать ее на несколько серверов. Нужно выбрать схему по которые мы будет ее партицировать.

**a. Range-Based Partitioning:** Мы можем партицировать базу на основе первой буквы ключа. Например все что начинается на **a** пойдет на один сервер, все что начинается на **b** на другой т.д. Этот подход называется Range-Based партицирование. Мы также можем объединять некоторые редкие сочетания символов в одну партицию.

Основаня проблема в этом подходе в том, что может возникнуть дизбаланс между серверами, если какие-то из символов в ключах встречаются сильно чаще или реже остальных.

**b. Hash-Based Partitioning:** В этом подходе мы берем хеш от объекта, который хотим сохранить и вычисляем хранилище на основе этого хеша. Хеширование позволяет распределить данные по партициям более равномерно. Например, наша функция хеширования всегда может возвращать рандомное значение от 1 до N, где N - общее количество серверов.

Этот подходит все еще может приводить к дизбалансу, который решается применением [Консистентного Хеширования](https://www.educative.io/collection/page/5668639101419520/5649050225344512/5709068098338816/)

### 8. Кеширование
Мы можем кешировать ссылки, которые часто запрашиваются. Можно использовать любое готовое решение типа Memchached, которое способно хранить ключи и соответствующие им ссылки. Сервер приложения может заглядывать в кеш за данными прежде чем искать ссылку у себя в хранилище.

**Сколько памяти нам нужно отвести под кеш?** Можно начать с 20% дневного трафика, а потом поправить это значение на основе опыта использования. Выше мы посчитали, что нам требуется 170 GB памяти, чтобы кешировать 20% дневного трафика. Современные сервера держат до 256 GB ОЗУ, так что можно легко уместить кеш на одном сервере. В качестве альтернативы можно использовать несколько серверов для кеширования.

**Какую стратегию вытеснени ключей нам стоит использовать?** Когда кеш полон и мы хотим добавить новую запись в него, как нам определить что можно выкинуть, а что стоит оставить? Можно использовать политику LRU (Least Recently Used). 

Для дальнейшего увеличения эффективности мы можем реплицировать наши кеширующие сервера для распределения нагрузки на них.

**Как мы будем обновлять реплики?** Каждый раз, когда данные отсутствуют в кеше, сервера приложений будут обращаться в базе данных. Каждый раз, когда это происходит, мы можем обновлять кеш на всех репликах. Если реплика уже имеет такую запись, она может игнорировать обновление.

![](attachments/Pasted%20image%2020220510163540.png)

### 9. Балансировка нагрузки (LB)
Мы можем добавить слой балансировки нагрузки в трех разных местах нашей системы:
- Между клиентом и серами приложений
- Между серверами приложений и базой данных
- Между серверами приложений и кешем

Для начала можно использовать равномерное распределение через Round Robin. Такая балансировка проста и эффективна в реализации. Если сервер умрет, его можно исключить из распределения.

Проблема может быть в том, что RR не учитывает нагрузку серверов. Как результат если сервер перегружен или работает медленно запросы могут его убить. Чтобы это обработать можно внедрить какое-нибудь более интеллектуальное решение, которое учитывает текущую нагрузку серверов.

### 10. Очистка БД
Должны ли записи в БД храниться бесконечно или их нужно удлять время от времени? Что должно происходить, когда время хранения ссылки истекает?

Если мы начнем постоянно искать и удалять протухшие ссылки, это создаст большую нагрузку на БД. Вместо этого мы можем медленно и лениво чистить базу. Наш сервис не будет отдавать протухшие ссылки, хотя они и могут оставать в базе дольше положенного.

- Каждый раз, когда пользователь обращается к протухней ссылке, мы можем возвращать ему ошибку и именно в этот момент удалять ссылку.
- Отдельный сервис может чистить базу в моменты минимальной нагрузки на нее.
- Можно указать дефолтное время жизни для ссылок, чтобы они точно не оставались в базе навечно.
- После удаления протухней ссылки, можно возвращать ее ключ обратно в key-DB.
- ![](attachments/Pasted%20image%2020220510165108.png)

### 11. Телеметрия
Скорее всего мы захотим знать сколько раз запросили тот или иной URL, откуда пришли посетители. Как нам хранить эту статистику? Если это будет часть строки в БД, которая хранит данные не загнемся ли мы с большим числом запросов на какой-то из популярных урлов?

### 12. Безопасность и ограничение доступа
Могут ли пользователи создавать приватные ссылки или ограничивать доступ к ссылкам для конкретных пользователей?

Мы можем сохранять уровень доступа (приватный/публичный) с каждой ссылкой в БД. Так же мы можем создать отдельную базу для хранения ID пользователей, которые имеют доступ к данной ссылке.

Если у пользователя нет доступа, можно отдавать ему HTTP-код 401.

## Сервис передачи коротких текстов Pastebin
Тут мы задизайним сервис типа Pasebin через который пользователи могут обмениваться фрагментами текста. Пользователи отправляют фрагмент текста и получают рандомно генерируемый URL для доступа к нему.

### 1. Что такое Pastebin?
Pastbin - это сервис в котором пользователи могут сохранять отрывки текста или картинки по сети и получать в ответ короткий URL для доступа к загруженным данным.

### 2. Требования и цели системы
**Функциональные требования:**
- Пользователи должны возможность загружать свои данные и получать уникальный URL для доступа к ним.
- Пользователи должны иметь возможность только загружать текст
- Данные и ссылки протухают через некоторое время. Пользователи должны иметь возможность задать собственное время жизни для контента.
- Пользователи должны иметь возможность задать собственный алиас для загруженного контента.

**Нефункциональные требования:**
- Система должна быть надежной, загруженные данные не должны теряться
- Система должна быть доступной, если она упадет, пользователи потеряют доступ к своему контенту.
- Данные должны быть доступны в реальном времени с минимальной задержкой.
- Ссылки не должны угадываться (быть предсказуемыми)

**Дополнительные требования:**
- Нужна аналитика (кто откуда и как часто имеет доступ к сервису)
- Нужен доступ через REST API для других сервисов

### 3. Некоторые аспекты дизайна
Pastebin очень похож на сервис сокращения ссылок. Но тут есть некоторые отличия, которые нужно держать в уме.

**Какой должен быть лимит загружаемых данных?** Мы можем ограничить размер одной записи скажем 10 МБ.

**Нужно ли ограничивать длину кастомных URL?** Пользователи могут задавать свои псевдонимы, но нет смысла делать их слишком длинными. Для единообразия можно ограничить их длину разумной границей. Сверху наверное это будет общая длинна ссылки 255 символов, но пусть у нас будет 20 символов.

### 4. Оценка емкости и ограничений
Сервис будет нагружен по чтению. Можем предположить что соотношение чтений к записи будет 5:1.

**Количество запросов:** Pastebin вряд ли будет также популярен как Twitter или Facebook. Предположим, что будет где-то миллион новых Паст каждый день. Это означает примерно 5M чтений Паст каждый день.

Новых Паст в секунду: 1M/(24 hours * 3600 sec) = 12 pastes/sec

Чтений Паст в секунду: 12 * 5 = 58 pastes/sec

**Хранилище:** Пользователи могут загружать до 10 MB данных за раз, но обычно грузят исходнико кода, конфиги, логи. Таким тексты занимают не так много места. Предположим, что в среднем запись будет занимать около 10 KB.

С такими оценками мы будем загружать около 10 GB данных в день: 1M * 10KB = 10 GB/day.

С 1M записей в день, за 10 лет мы накопим  3.6 B записей. Нам нужно генерировать уникальный ключ для них. Если использовать base64 ([A-Z, a-z, 0-9, ., -]) для кодирования ключа, нас устроит длина в 6 символов: 64^6 = 68 B уникальных строк.

Если на каждый символ ключа мы затратим 1 байт, то для всех ключей нам понадобится: 3.6 B * 6 bytes = 22 GB. Это пренебрежительно мало по сравнении с местом требуемым под данные.

За 10 лет накопится 36 TB данных. Нам стоит оставить запас в хранилище, чтобы оно ни при каких условиях не было заполнено больше, чем на 70%, таким образом для хранение данных нам нужно будет хранилище в 51.5 TB.

**Трафик:** Для запросов на запись мы ожидаем 12 RPS, итого 12 * 10KB = 120 KB/s

Для запросов на чтение мы ожидаем 58 RPS, так получим 58 * 10KB = 600 KB/s

**Оперативная память:** Мы можем кешировать наиболее популярые Пасты. Возьмем примерное распределение 20/80 и будем кешировать 20% запросов на чтение.

Поскольку у нас 5M запросов на чтение в день, нам понадобится 0.2 * 5M * 10KB = 10 GB памяти.

### 5. API системы
Сервис можно предоставлять через SOAP или REST. Апишка может выглядеть примерно так.

```
addPaste(api_dev_key, paste_data, custom_url=None, user_name=None, paste_name=None, expire_date=None)

getPaste(api_dev_key, api_paste_key)

deletePaste(api_dev_key, api_paste_key)
```

### 6. Дизайн БД
- Нам нужно хранить миллиарды записей
- Метаданные невелики (меньше 1К на запись)
- Каждая Паста может быть среднего размера (несколько MB)
- Между записями нет отношений, кроме записей о пользователе, который создал запись.
- Сервис нагружен по чтению

Для хранения данных нам может понадобиться 2 таблицы: для хранения самих данных и для хранения данных о пользователях

![](attachments/Pasted%20image%2020220510202220.png)

Тут URLHash - это ссылка аналогичная оной в сокращалке ссылок, а ContenKey - это ссылка на объект во внешне хранилище.

### 7. Общий дизайн
На высоком уровне нам понадобится уровень приложения для обработки запросов пользователя и уровень хранения данных к которым будет обращаться сервер приложений. Мы можем разделить базы на отдельное хранилище для метаданных и отдельное объектное хранилище типа Amazon S3 для хранения содержимого Паст. Это позволит нам масштабировать их независимо.

![](attachments/Pasted%20image%2020220510202546.png)

### 8. Дизайн компонентов
#### a. Уровень приложения
Уровень приложения должно обрабатывать все входящие и исходящие запросы. Сервер приложений взаимодействует с бекендом хранения.

**Как обрабатывать запросы на запись?** Получив запрос на запись сервер приложения должен сгенерировать 6-символьную случайную строку которая будет являться ключем для доступа к данных (исли пользователь не предоставил свой ключ). После этого он должен сохранить содержимое пасты и сгенерированный ключ в БД. После успешного сохранения сервер должен вернуть ключ пользователю.

Одной из проблем тут может быть то, что сгенерированный ключ уже находится в базе. В этом случае мы должны сгенерировать новый ключ и попробовать сохранить данные еще раз, и делать так до тех пор пока данные не удастся сохранить нормально. Если же в базе существует кастомный ключ пользователя, то тут уж останется только вернуть ошибку.

Другим решением для этой проблемы может быть использование отдельного сервиса генерации ключей (Key Generation Service aka KGS), который должен генерировать уникальные ключи заранее и сохранять их в базу ключей (key-DB). Суть такого сервиса подробно описана в описании сервиса сокращения ссылок.

**Каким образом обрабатывается запрос на чтение?** Получив запрос на чтение, сервис приложения обращется к хранилищу данных. Хранилище ищет ключ и, если находит, возващает содержимое Пасты.

#### b. Уровень хранения данных
Мы можем разделить уровень хранения на две части:
- Хранилище метаданных. Мы можем использовать реляционную базу типа MySQL или распределенное KV-хранилище типа Dynamo или Cassandra.
- Объектное хранилище. Мы можем сохранять контент в Объектном хранилище типа Amazon S3. Каждый раз, когда мы будет приближаться к лимиту хранилища, его можно будет легко расширить.
 
![](attachments/Pasted%20image%2020220510205325.png)

### 9. Очистка БД
### 10. Партицирование и репликация
### 11. Кеширование и балансировка нагрузки
### 12. Безопасность и права доступа
В этом плане все тоже самое, что и в сервисе сокращения ссылок. Можно почитать там.



