# Recipe: Messaging and Kafka
Эта глава описывает интеграцию микросервисов посредством message-oriented middleware (MOM). MOM служит для отправки событий и гарантирует что оно достигнет получателя.

Характеристики MOM:
- Высокая надежность
- Низкая задержка
- Высокая пропускная способность

## Message-oriented Middleware (MOM)
Микросервисы развязываются с помощью MOM. Один микросервис отправляет сообщение, другой принимает его из очереди. Это означает, что отправитель и реципиент не знаю друг друга. Таким образом исчезает нужна в service descovery. Отправитель и реципиент находят друго друга по топику или очереди через готорую они обмениваются сообщениями.

Балансировка нагрузки так же проста. Если несколько реципиентов получают сообщения из одной очереди, нагрузка естественным образом балансируется на всех них.

В тоже время MOM - это сложный и зрелый продукт, который обслаживает все коммуникации и должен гарантировать высокую надежность и высокую пропускную способность. Для этого нужно знать как его правильно конфигурировать и использовать.

### Варианты MOM
- Java Messaging System (JMS) - это стандартизированный API для Java и часть стандарта Java EE. Самые известные реализации JMS - это [Apache ActiveMQ](http://activemq.apache.org/) и [IBM MQ](http://www-03.ibm.com/software/products/en/ibm-mq), который раньше был известен как IDM MQSeries.
- Advanced Message Queuing Protocol (AMQP) - это сетевой прокотол поверх TCP/IP. Его реализуют [RabbitMQ](https://www.rabbitmq.com/), [Apache ActiveMQ](http://activemq.apache.org/), и [Apache Qpid](https://qpid.apache.org/).
- [ZeroMQ](http://zeromq.org/) - это библиотека, использование которой не требует отдельного брокера.
- [MQTT](http://mqtt.org/) - это протокол обмена сообщениями играющий важную роль в интернете вещей (IoT).

Для минимизации риска лучше всего использовать уже готовые известные MOM.

## Архитектура Kafka
Кафка хорошо подходит для микросервисов. Вместе с обычными фичами МОМ типа высокой пропускной способности и низкой задеркой, Кафра может компенсировать сбои отдельных серверов через репликацию и может масштабироваться на большое количество серверов.

### Кафка сохраняет историю сообщений
Обычно MOM предназначен только для доставки сообщений, но Кафка может хранить длительную историю сообщений.

Кафка также поддерживает стриминг сообщений, приложение может получить данные из кафки, обработать их и закинуть обратно в Кафку.

### API
Кафка предоставляет отдельные интерфейсы для каждого из трех сценария использования MOM:
- Produser API предназначен для отправки сообщений
- Consumer API предназначен для получения сообщений
- Streams API служит для трансформации данных

Kafka написана на Java, однако API могут использоваться клиентами на любом языке.

### Записи (Records)
Кафка организует данные в записи (records) - это то, что в других MOM называется сообщениями.

Записи содержат передаваемые данные в качестве значения (value), которые она считает темным ящиком и не лезет внутрь. В добавок к этому записи имею ключ и метку времени.

### Топики (Topics)
Топик - это именовынное множество записей. Продюсеры отправляют записи в топик, а консюмеры получают их из топиков.

Например, интернет магазин для обмена данным о заказах может использовать топик "order", а для обмена данными о пользователям топик "customer".

### Партиции (Partitions)
Топики делятся на партиции. Партиции позволяют гарантировать строгий порядок записей, а так же паралелльную их обработку.

![](attachments/Pasted%20image%2020220502223728.png)
Когда продюсер создает новую запись, она добавляется в партицию. Таким образом каждая запись сохраняется только в одну партицию.

Записи обычно привязываются к партиции путем вычисления хеша от ключа записи, но продюсер может реализовать и свой алгоритм распределения.

Для каждого партишена гарантируется порядок записей в ней, т.е. порядок в котором записи были добавлены в партишн - это и порядок в котором они будут прочитаны консюмером. В случае чтения из нескольких партишенов порядок чтения записей не гарантируется. Чтение из партиции линейно. Если требуется параллельная обработка, косюмер (или несколько консюмеров) должен читать из нескольких партиций.

Большое количество партиций обладает [интересными эффектами](http://www.confluent.io/blog/how-to-choose-the-number-of-topicspartitions-in-a-kafka-cluster/) Они позволяют больший параллелизм, но требуют больших ресурсов. Имеет смысл иметь достаточное количество партиций, но не слишком большое. Обычно их число держится в пределах нескольких сотен.

В принципе, партиция - это просто файл в который добавляются записи. Добавление записей в конец файла - одна из самых быстрых и простых операций для массовых дисковых хранилищ.

### Коммиты (Commit)
Для каждого консюмера Кафка запоминает смещение в каждой партиции. Смещение определяет какую запись в партиции консюмер прочитал и обработал последней. Это помогает Кафке гарантировать, что каждая запись будет в итоге обработана.

После обработки очередной записи консюмер коммитит новое смещение. Конечно консюмер может закомитить записи и до того как они обработаны, таким образом возможно, что некоторые записи не будут обработаны вообще никогда.

Консюмер может коммитить сразу несколько записей, таким образом можно выиграть в производительности, но это может привести к возникновению дубликатов. Например консюмер взял пачку записей и сломался на обработке половины из них. Поскольку они не были закоммичены, после рестарта Кафка вернет снова все записи, так что некоторые из них должны будут быть обработаны повторно.

Кафка поддерживает [exactly once](https://www.confluent.io/blog/exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it/) доставку сообщений.

### Поллинг (Polling)
Консюмеры вытягивают данные из Кафки и обрабатывают их. Это противоположно тому, что происходит с серверами очередей, которые сами пушат события клиентам.

Это позволяет консюмерам самим решать когда и сколько записей обрабатыать, т.е. самостоятельно регулировать свою нагрузку.

Обычо сам процесс полинга спрятам в глубинах библиотеки для работы с Кафкой, разработчику остается лишь обрабатывать отдельные записи.

![](attachments/Pasted%20image%2020220502235701.png)

### Репликация
Партиции хранят данные. Поскольку данны в одной партиции независимы от данных в других партициях, партиции могут быть распределены между разными серверами:
- Каждый сервер обрабатывает отдельные партиции - это позволяет балансировать нагрузку.
- При повышении нагрузки необходимо добавить новые сервера и перераспределить по ним существующие партиции.
- Партиции так же могут быть реплицированы, т.е. обрабатываться сразу на нескольких серверах, что делат Кафку устойчивой к сбоям.

### Пример
- Допустим, сущестует N реплик. При записи мы можем определить сколько сихнронизированных реплик должны подтвердить изменения.
- При N = 3 и двух синхронных репликах кластер останется доступным даже если одна из реплик сдохнет.
- Если один из серверов сдохнет, новые записи все еще можно будет добавлять в две реплики. Если реплика сдохнет, данные не будут потеряна потому что каждая операция записи подтверждается как минимум двумя репликами.
- Даже если реплика потеряется вовсе, данные все еще должны будут быть сохранены хотя бы в одной дополнительной реплике.

### Leader and Follower
Запись происходит на лидера (master) и реплицируется на фолловеров (слейвов). Продюсер может закинуть на мастер сразу пакет данных (batch).

### Переотправка
Если отправить сообщение в очередь не удалось, продюсер может указать API, что сообщение нужно отправить снова. Если оно вдруг отправилось в первый раз, но подтверждение этому не пришло, может возникнуть дубликат сообщения. Настройки по-умолчанию указывают, что перепосылать сообщения не нужно.

Так же возможна идемпотентная отправка сообщений. И продюсер и консюмер должны это поддерживать.

### Группа консюмеров (Consumer Group)
Консюмеры огранизуютя в группы в которых каждая партиция вычитывается только одним консюмером.  Один консюмер может вычитывать данные из нескольких партиций.

![](attachments/Pasted%20image%2020220503001700.png)

Таким образом консюмер получает сообщения из одной или нескольких партиций.

### Пример
На картинке выше консюмер 1 читает сообщения из партиции 1 и 2, консюмер 2 получает сообщения из партиции 3.

Когда консюмер получает сообщение из партиции, он так же позже получит и другие сообщения из этой же партиции. Порядок сообщения в одной партиции сохраняется. Консюмер может читать параллельно из нескольких партиций.

Таким образом инстанс получивший сообщение neworder42 так же получит и updatedorder42, если они были отправлены в ту же партицию.

Это все применимо, если распределение консюмеров по партициям остается неизменным. Если вдруг в группу добавится новый консюмер, ему придется дочитывать сообщения за кем-то другим.

Максимальное количество консюмеров в группе ограничено количеством партиций. Их может быть и больше, но лишние консюмеры будут простаивать.

Консюмеры всегда являются членами какой-либо группы, если каждый из них должен получать все записи партиции, значит должны быть отдельные группы на каждого консюмера.

### Хранение данных (Persistence)
Кафка является смесью системы обмена сообщениями и базы данных. Сообщения могут быть записаны продюсером и получены консюмером. Время хранения (retention) для записей по-умолчанию 7 дней, но его можно изменить. Записи также можно вовсе не удалять. Таким образом новый консюмер может перечитать вообще все когда бы то ни было отправленные сообщения.

### Сжатие лога (Log compation)
Со времнем некоторые данные становятся не нужны, для их удаления существует сжатие лога. Все записи с идентичными ключами удаляются (а ключи-то могут быть не уникальными!!!), поэтому очень важно грамотно выбирать значение ключей.

Например, сжатие лога топика в котором хранится информация о заказах удалит все события с ключем updated42, таким образом в Кафке останется только последнее обновление заказа.

## События с Кафкой
Системы, которые коммуницируют с помощью Кафки могут легко обмениваться событиями:
- Записи могут сохраняться перменентно и консюмеры могут читать историю событий и перестраивать свой стейт. Консюмерам не нужно сохранять историю событий локально.
- Это означает, что все релеватная информация должна быть сохранена в записях Кафки.
- Если событие становится нерелевантным, данные могут быть удалены через механизм сжатия логов Кафки.
- С помощью группы консюмеров Кафка может гарантировать что один консюмер обрабатывает все записи топика. Это может упростить обработку когда в примеру тольк оодин консюмер должен создавать и записывать инвойсы в базу.

### Отправка событий
Продюсер может отправлять события в различные моменты:
- После выполнения действия. Например сервис обрабатывает заказ и только потом уведомляет остальные сервисы, что заказ обработан. В этом случае продюсер может изменить данные заказа в базе или вовсе не отправить событие, если обработка заказа закончилась неудачей.
- Перед выполнением действия. Когда приходит новый заказ сервис сначала может отправить об этом событие, а потом уже обрабатывать новый заказ. Это не совсем адекватно, т.к. событие должно говорить о чем-то что уже произошло. К тому же, если произойдет ошибка, сообщение уже будет отправлено, его невозможно будет вернуть. К тому же отправка сообщения перед обработкой задерживает эту самую обработку заказа.
- Также возможно накопление событий в базе и отправка их потом пакетом. В этом случае запись данных в базу и генерация данных для события может происходить в рамках одной транзакции. Этот вариант так же может повысить пропускную способность за счет группировки событий, но он же увеличивает задержку - изменения попадут в Кафку только после того как весь пакет данных будет обработан.

## Пример архитектуры
Сервис microservice-kafka-order создает заказы и отправляет события об этом в топик заказов. Таким образом он является продюсером.

Сервисы microservice-kafka-invoicing и microservice-kafka-shipping чититывают события заказов в двух отдельных группах консюмеров. 

У каждого сервиса всего один инстанс.

![](attachments/Pasted%20image%2020220503012130.png)

Сервисы invoicing и shipping требуют разной информации:
- Invoicing требует биллинг адрес и информацию о стоимости заказанных товаров
- Shipping требует адрес доставки и не требуются стоимость

Оба микросервиса читают нужную информацию из одного и того же топика Кафки и одних и тех же записей. Разница только в том какие именно данные они получают из события. Технически это очень просто, т.к. сама информация хранится в виде JSON и сервисы спокойно могут игнорировать значения полей, которые им не инетересны.

### Дизайн предметной области и стратегический дизайн
В данном примере коммуникация и преобразование данных намеренно упрощено.

Сервисы реализуют DDD-паттерн "Публичный язык". События о заказах имеют стандартизированный формат и все другие сервисы вычитавают оттуда нужные им данные. 

С ростом количества потребителей событий, модель данных может сильно распухнуть. В этом случае может быть применем шаблон "Постащик/Потребитель". Команды ответственные за Invoicing и Shipping могут диктовать команде заказов какие данные им нужно помещать в событие. В дальнейшем интерфейс может быть разделен.

Разделение может сделать более очевидным какие данные какому потребителю требуются, а так же упростить разработку и доработку под отдельных подтребителей.

